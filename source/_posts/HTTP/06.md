---
title: http 2.0
date: 2018-05-09
categories: Http
tags: Http
toc: true
thumbnail: https://gitee.com/heptaluan/backups/raw/master/cdn/cover/06.jpg
---

先回顾一下 `http` 相关知识

<!--more-->




## http 协议的特点

1. 支持客户和服务器模式

2. 简单快速：客户向服务器请求服务时，只需要传送请求方法和路径，请求方法常用的有 `GET`，`POST`，`HEAD` 等，每种方法规定了客户与服务器联系的类型不同，由于 `http` 协议简单，使得 `http` 服务器的程序规模小，因而通讯速度很快

3. 灵活：`http` 允许传输任意类型的数据对象，正在传输的类型由 `Content-Type` 加以标记

4. 无连接：无连接的含义是限制每次连接只处理一个请求，服务器处理完客户的请求并收到客户的应答后，即断开连接，采用这种方式可以节省传输时间

5. 无状态：`http` 协议是无状态协议，无状态是指协议对于事物处理没有记忆能力，缺少状态意味着如果后续处理需要前面的信息，则它必须重传，这样可能导致每次连接传送的数据量增大，另一方面，在服务器不需要先前信息的时候它的应答就较快



## http/1.0 的缺点

`http/1.0` 版本主要的缺点是，每个 `tcp` 连接只能发送一个请求，发送数据完毕，连接就关闭，如果还需要请求其他资源，就必须再新建一个连接

为了解决这个问题，有些浏览器在请求的时候，使用了一个非标准的 `Connection` 字段

```js
Connection: keep-alive
```

这个字段要求服务器不关闭 `tcp` 连接，以便其他请求复用，服务器同样回应这个字段

```js
Connection: keep-alive
```


## http/1.1

`1.1` 版本的最大的变化，就是引入了持久连接（`persistent connection`），即 `tcp` 连接默认不关闭，可以被多个请求复用，不用声明 `Connection: keep-alive`

客户端和服务器发现对方一段时间没有活动，就可以主动关闭连接，不过，规范的做法是，客户端在最后一个请求的时候，发送 `Connention: close`，明确要求服务器关闭 `tcp` 连接



## 管道机制

`1.1` 版本还引入了管道机制（`pipelining`），即在同一个 `tcp` 连接里面，客户端可以同时发送多个请求

例如客户端需要请求两个资源，以前的做法是，在同一个 `tcp` 连接里面，先发送 `A` 请求，然后等待服务器做出回应，收到后再发出 `B` 请求

管道机制则是允许浏览器同时发出 `A` 请求和 `B` 请求，但是服务器还是按照顺序，先回应 `A` 请求，完成后再回应 `B` 请求



## http/1.1 缺点

虽然 `1.1` 版允许复用 `tcp` 连接，但是同一个 `tcp` 连接里面，所有的数据通信是按次序进行的，服务器只有处理完一个回应，才会进行下一个回应

要是前面的回应特别慢，后面就会有许多请求排队等着，这称为队头堵塞（`Head-of-line blocking`）

为了避免这个问题，只有两种方法：一是减少请求数，二是同时多开持久连接



## http/2

主要涉及二进制帧，多路复用，请求优先级，流量控制，服务器端推送以及首部压缩等新改进

#### 二进制协议

`http/1.1` 版本的头信息肯定是文本（`ASCII` 编码），数据体可以是文本，也可以是二进制

`http/2` 则是一个彻底的二进制协议，头信息和数据体都是二进制，并且统称为帧（`frame`，头信息帧和数据帧）

* 在二进制分帧层中，`http/2` 会将所有传输的信息分割为更小的消息和帧（`frame`），并对它们采用二进制格式的编码

* 其中 `http1.x` 的首部信息会被封装到 `HEADER frame`，而相应的 `Request Body` 则封装到 `DATA frame` 里面

* `http/2` 通信都在一个连接上完成，这个连接可以承载任意数量的双向数据流

所以简单来说就是

* 单连接多资源的方式，减少服务端的链接压力，内存占用更少，连接吞吐量更大

* 由于 `tcp` 连接的减少而使网络拥塞状况得以改善，同时慢启动时间的减少，使拥塞和丢包恢复速度更快




#### 多工

`http/2` 复用 `tcp` 连接，在一个连接里，客户端和浏览器都可以同时发送多个请求或回应，而且不用按照顺序一一对应，这样就避免了队头堵塞

例如在一个 `tcp` 连接里面，服务器同时收到了 `A` 请求和 `B` 请求，于是先回应 `A` 请求，结果发现处理过程非常耗时

于是就发送 `A` 请求已经处理好的部分， 接着回应 `B` 请求，完成后，再发送 `A` 请求剩下的部分

这样双向的、实时的通信，就叫做多工（`Multiplexing`）



#### 数据流（连接共享）

因为 `http/2` 的数据包是不按顺序发送的，同一个连接里面连续的数据包，可能属于不同的回应，因此必须要对数据包做标记，指出它属于哪个回应

`http/2` 将每个请求或回应的所有数据包，称为一个数据流（`stream`），每个数据流都有一个独一无二的编号，数据包发送的时候，都必须标记数据流 `id`，用来区分它属于哪个数据流

另外还规定，客户端发出的数据流，`id` 一律为奇数，服务器发出的，`id` 为偶数

数据流发送到一半的时候，客户端和服务器都可以发送信号（`RST_STREAM` 帧），取消这个数据流

* `1.1` 版取消数据流的唯一方法，就是关闭 `tcp` 连接

* `http/2` 可以取消某一次请求，同时保证 `tcp` 连接还打开着，可以被其他请求使用

`http/2` 里的每个 `stream` 都可以设置又优先级（`Priority`）和依赖（`Dependency`）

* 优先级高的 `stream` 会被 `server` 优先处理和返回给客户端

* `stream` 还可以依赖其它的 `sub streams`（优先级和依赖都是可以动态调整的）

* 客户端还可以指定数据流的优先级，优先级越高，服务器就会越早回应




#### 头信息压缩

`http` 协议不带有状态，每次请求都必须附上所有信息，所以请求的很多字段都是重复的

比如 `Cookie` 和 `User Agent`，一模一样的内容，每次请求都必须附带，这会浪费很多带宽，也影响速度

`http/2` 对这一点做了优化，使用了专门为首部压缩而设计的 `HPACK` 算法，引入了头信息压缩机制（`header compression`）

* 一方面，头信息使用 `gzip` 或 `compress` 压缩后再发送

* 另一方面，客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号，以后就不发送同样字段了，只发送索引号，这样就提高速度了



#### 服务器推送

`http/2` 允许服务器未经请求，主动向客户端发送资源，这叫做服务器推送（`server push`）

常见场景是客户端请求一个网页，这个网页里面包含很多静态资源，正常情况下客户端必须收到网页后，解析 `html` 源码，发现有静态资源，再发出静态资源请求

其实，服务器可以预期到客户端请求网页后，很可能会再请求静态资源，所以就主动把这些静态资源随着网页一起发给客户端了





## 参考

[http2 讲解](http://www.kancloud.cn/kancloud/http2-explained/49812)

[http/2 资料汇总](https://imququ.com/post/http2-resource.html#comments)

[http2 explained](https://daniel.haxx.se/http2/)

[Hypertext Transfer Protocol Version 2 (http/2)](http://httpwg.org/specs/rfc7540.html)

[http/2.0 相比 1.0 有哪些重大改进？](https://www.zhihu.com/question/34074946)
