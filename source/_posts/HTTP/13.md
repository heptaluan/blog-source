---
title: HTTP 查漏补缺
date: 2020-09-19
categories: HTTP
tags: HTTP
toc: true
thumbnail: https://gitee.com/heptaluan/backups/raw/master/cdn/cover/13.jpg
---

本章记录的是一些 `HTTP` 相关内容的补充，偏向于查漏补缺，主要是一些平常遇到或是看到过的知识点，面试题之类的，在这里简单的整理汇总一下，一方面补充些专业知识，另一方面也是方便以后查询或是复习，更多相关内容可以参考 [计算机网络知识梳理](https://heptaluan.github.io/2020/08/08/HTTP/00/) 和 [前端知识体系整理](https://heptaluan.github.io/target/)

<!--more-->


## HTTP 协议优缺点

* `HTTP` 特点
  * 灵活可扩展，一个是语法上只规定了基本格式，空格分隔单词，换行分隔字段等，另外一个就是传输形式上不仅可以传输文本，还可以传输图片，视频等任意数据
  * 请求/响应 模式，通常而言，就是一方发送消息，另外一方要接受消息，或者是做出相应等
  * 可靠传输，`HTTP` 是基于 `TCP/IP`，`TCP` 提供可靠的字节流服务，`IP` 协议的作用是把各种数据传送给对方
* `HTTP` 缺点
  * 无连接，限制每次连接只处理一个请求，服务器处理完客户的请求，并收到客户的应答后，即断开连接
  * 无状态，对于事务处理没有记忆能力，即服务器不知道客户端是什么状态
  * 明文传输，协议里的报文不使用二进制数据，而是文本形式，这让 `HTTP` 的报文信息暴露给了外界，给攻击者带来了便利
  * 队头阻塞，当 `HTTP` 开启长连接时，共用一个 `TCP` 连接，当某个请求时间过长时，其他的请求只能处于阻塞状态，这就是队头阻塞问题


## HTTP 协议各版本差异

* `HTTP/0.9`
  * `1991` 年发布的原型版本，功能简陋，只有一个命令 `GET`，只支持纯文本内容
* `HTTP/1.0`
  * 任何格式的内容都可以发送，另外还引入了 `POST` 命令和 `HEAD` 命令
  * `HTTP` 请求和回应的格式改变，除了数据部分，每次通信都必须包括头信息，用来描述一些元数据
  * 只使用请求头中的 `If-Modified-Since` 和 `Expires` 字段作为缓存失效的标准
  * 不支持断点续传，也就是说，每次都会传送全部的页面和数据
  * 通常每台计算机只能绑定一个 `IP`，所以请求消息中的 `URL` 并没有传递主机名
* `HTTP/1.1`
  * 引入了持久连接
    * `TCP` 连接默认不关闭，可以被多个请求复用，不用声明 `Connection: keep-alive`，长连接的连接时长可以通过请求头中的 `keep-alive` 来设置
  * 引入了管道机制
    * 在同一个 `TCP` 连接里，客户端可以同时发送多个请求
  * 新增缓存控制标头
    * 添加了 `E-tag`，`If-Unmodified-Since`，`If-Match`，`If-None-Match` 等缓存控制标头来控制缓存失效
  * 支持断点续传
    * 通过使用请求头中的 `Range` 来实现
  * 使用了虚拟网络
    * 在一台物理服务器上可以存在多个虚拟主机，并且它们共享一个 `IP` 地址
  * 新增方法 `PUT`、`PATCH`、`OPTIONS`、`DELETE`
* `HTTP/2`
  * 二进制分帧
    * 采用二进制格式，这样报文格式就被拆分为一个个乱序的二进制帧，用 `Headers` 帧存放头部字段，`Data` 帧存放请求体数据等，因为不需要排队等待，一定程度上解决了队头阻塞问题
  * 头部压缩
    * `HTTP/1.1` 版本会出现 `User-Agent/Cookie/Accept/Server/Range` 等字段可能会占用几百甚至几千字节，而 `Body` 却经常只有几十字节，导致头部偏重，`HTTP/2` 使用 `HPACK` 算法进行压缩
  * 多路复用
    * 复用 `TCP` 连接，在一个连接里，客户端和浏览器都可以同时发送多个请求或回应，且不用按顺序一一对应，一定程度上解决了队头阻塞的问题
  * 服务器推送
    * 允许服务器未经请求，主动向客户端发送资源，即服务器推送
  * 请求优先级
    * 可以设置数据帧的优先级，让服务端先处理重要资源，优化用户体验
* `HTTP/3`
  * `QUIC` 协议
    * 运行在 `QUIC` 之上的 `HTTP` 协议被称为 `HTTP/3`，`QUIC` 协议基于 `UDP` 实现，同时也整合了 `TCP`、`TLS` 和 `HTTP/2` 的优点，并加以优化
  * 零 `RTT` 建立连接
    * 首次连接只需要 `1 RTT`，后面的连接更是只需 `0 RTT`，意味着客户端发给服务端的第一个包就带有请求数据
  * 连接迁移
    * `QUIC` 连接不以四元组（源 `IP`、源端口、目的 `IP`、目的端口）作为标识，而是使用一个 `64` 位的随机数，这个随机数被称为 `Connection ID`，即使 `IP` 或者端口发生变化，只要 `Connection ID` 没有变化，那么连接依然可以维持
  * 多路复用
    * `QUIC` 的传输单元是 `Packet`，加密单元也是 `Packet`，整个加密、传输、解密都基于 `Packet`，这样就能避免 `TLS` 的队头阻塞问题
    * `QUIC` 基于 `UDP`，`UDP` 的数据包在接收端没有处理顺序，即使中间丢失一个包，也不会阻塞整条连接，其他的资源会被正常处理
  * 改进的拥塞控制
    * 热插拔，`TCP` 中如果要修改拥塞控制策略，需要在系统层面进行操作，`QUIC` 修改拥塞控制策略只需要在应用层操作，并且 `QUIC` 会根据不同的网络环境、用户来动态选择拥塞控制算法
    * 前向纠错 `FEC`，使用前向纠错（`FEC`，`Forward Error Correction`）技术增加协议的容错性，一段数据被切分为 `10` 个包后，依次对每个包进行异或运算，运算结果会作为 `FEC` 包与数据包一起被传输，如果不幸在传输过程中有一个数据包丢失，那么就可以根据剩余 `9` 个包以及 `FEC` 包推算出丢失的那个包的数据
    * 单调递增的 `Packet Number`，与 `TCP` 的 `Sequence Number` 不同的是，`Packet Number` 严格单调递增，如果 `Packet N` 丢失了，那么重传时 `Packet` 的标识不会是 `N`，而是比 `N` 大的数字，比如 `N + M`，这样发送方接收到确认消息时就能方便地知道 `ACK` 对应的是原始请求还是重传请求
    * 更多的 `ACK` 块，`QUIC` 最多可以捎带 `256` 个 `ACK block`，在丢包率比较严重的网络下，更多的 `ACK block` 可以减少重传量，提升网络效率
  * 流量控制
    * `TCP` 会对每个 `TCP` 连接进行流量控制，而 `QUIC` 只需要建立一条连接，在这条连接上同时传输多条 `Stream`



## 队头阻塞问题

关于队头阻塞问题，其实在整理 `HTTP/1.1`，`HTTP/2` 和 `HTTP/3` 相关内容的时候都有所涉及，但是可能是东一点西一点分散在各处，所以在这里就简单的汇总和梳理一下


#### 什么是队头阻塞？

对于每一个 `HTTP` 请求而言，这些任务是会被放入一个任务队列中串行执行的，一旦队首任务请求太慢时，就会阻塞后面的请求处理，这就是 `HTTP` 队头阻塞问题，队头阻塞会导致带宽无法被充分利用，以及后续健康请求被阻塞，假设有五个请求同时发出，如下图

![](https://gitee.com/heptaluan/backups/raw/master/cdn/http/11-01.png)

在第一个请求没有收到回复之前，后续从应用层发出的请求只能排队，请求 `2，3，4，5` 只能等待请求 `1` 的响应回来之后才能逐个发出，网络通畅的时候性能影响不大，一旦请求 `1` 因为什么原因没有抵达服务器，或者响应因为网络阻塞没有及时返回，影响的就是所有后续请求


#### 如何解决

在 `HTTP/1.1` 当中，为了解决队头阻塞带来的延迟，协议设计者设计了一种新的 `HTTP` 管线化机制（`pipelining`），管线化的流程图可以用下图表示

![](https://gitee.com/heptaluan/backups/raw/master/cdn/http/11-04.png)

和之前相比最大的差别是，请求 `2，3，4，5` 不需要等待请求 `1` 的响应返回之后才发出，而是几乎在同一时间就把请求发向了服务器，`2，3，4，5` 及所有后续共用该连接的请求节约了等待的时间，极大的降低了整体延迟，下图可以清晰的看出这种新机制对延迟的改变

![](https://gitee.com/heptaluan/backups/raw/master/cdn/http/11-05.png)

不过管线化并不是完美的，它也存在不少缺陷

* 管线化只能适用于 `HTTP/1.1` ，一般来说，支持 `HTTP/1.1` 的服务端都要求支持管线化
* 只有幂等的请求（`GET`，`HEAD`）能使用管线化，非幂等请求比如 `POST` 不能使用，因为请求之间可能会存在先后依赖关系
* 队头阻塞并没有完全得到解决，服务端的响应还是要求依次返回，遵循 `FIFO`（`first in first out`）原则，也就是说如果请求 `1` 的响应没有回来，`2，3，4，5` 的响应也不会被送回来
* 绝大部分的 `HTTP` 代理服务器不支持管线化

正是因为有这么多的问题，各大浏览器厂商要么是根本就不支持管线化，要么就是默认关掉了管线化机制，而且启用的条件十分苛刻，可以参考 `Chrome` 对于管线化的 [问题描述](https://www.chromium.org/developers/design-documents/network-stack/http-pipelining)

接下来，在 `HTTP/2` 当中提出了多路复用（`multiplexing`）的解决方案（源自 `SPDY`），多路复用允许同时通过单一的 `HTTP/2` 连接发起多重的 请求/响应 消息，众所周知在 `HTTP/1.1` 协议中，浏览器客户端在同一时间，针对同一域名下的请求有一定数量限制，超过限制数目的请求会被阻塞，也就是如果想并发多个请求，必须使用多个 `TCP` 链接

这也是为何一些站点会有多个静态资源 `CDN` 域名的原因之一，目的就是变相的解决浏览器针对同一域名的请求限制阻塞问题，而 `HTTP/2` 的多路复用（`Multiplexing`）则允许同时通过单一的 `HTTP/2` 连接发起多重的 请求/响应 消息

![](https://gitee.com/heptaluan/backups/raw/master/cdn/http/11-15.png)

因此 `HTTP/2` 可以很容易的去实现多流并行而不用依赖建立多个 `TCP` 连接，`HTTP/2` 把 `HTTP` 协议通信的基本单位缩小为一个一个的帧，这些帧对应着逻辑流中的消息，并行地在同一个 `TCP` 连接上双向交换消息

`HTTP/2` 虽然可以解决请求这个粒度的阻塞，但 `HTTP/2` 的基础 `TCP` 协议本身却也存在着队头阻塞的问题，`HTTP/2` 的每个请求都会被拆分成多个 `Frame`，不同请求的 `Frame` 组合成 `Stream`，`Stream` 是 `TCP` 上的逻辑传输单元，这样 `HTTP/2` 就达到了一条连接同时发送多条请求的目标，这就是多路复用的原理

我们看一个例子，在一条 `TCP` 连接上同时发送 `4` 个 `Stream`，其中 `Stream1` 已正确送达，`Stream2` 中的第 `3` 个 `Frame` 丢失，`TCP` 处理数据时有严格的前后顺序，先发送的 `Frame` 要先被处理，这样就会要求发送方重新发送第 `3` 个 `Frame`，`Stream3` 和 `Stream4` 虽然已到达但却不能被处理，那么这时整条连接都被阻塞

![](https://gitee.com/heptaluan/backups/raw/master/cdn/http/12-09.png)

不仅如此，由于 `HTTP/2` 必须使用 `HTTPS`，而 `HTTPS` 使用的 `TLS` 协议也存在队头阻塞问题，`TLS` 基于 `Record` 组织数据，将一堆数据放在一起（即一个 `Record`）加密，加密完后又拆分成多个 `TCP` 包传输，一般每个 `Record` 有 `16K` 左右，包含 `12` 个 `TCP` 包，这样如果 `12` 个 `TCP` 包中有任何一个包丢失，那么整个 `Record` 都无法解密

![](https://gitee.com/heptaluan/backups/raw/master/cdn/http/12-10.png)

队头阻塞会导致 `HTTP/2` 在更容易丢包的弱网络环境下比 `HTTP/1.1` 更慢，所以就有了 `HTTP/3` 当中的 `QUIC` 协议，那么 `QUIC` 是如何解决队头阻塞问题的呢？主要有两点

* `QUIC` 的传输单元是 `Packet`，加密单元也是 `Packet`，整个加密、传输、解密都基于 `Packet`，这样就能避免 `TLS` 的队头阻塞问题
* `QUIC` 基于 `UDP`，`UDP` 的数据包在接收端没有处理顺序，即使中间丢失一个包，也不会阻塞整条连接，其他的资源会被正常处理

![](https://gitee.com/heptaluan/backups/raw/master/cdn/http/12-11.png)


## HTTP 数据传输

这里主要分为定长数据与不定长数据的处理，我们一个一个来看

#### 定长数据

对于定长的数据包而言，发送端在发送数据的过程中，需要设置 `Content-Length`，来指明发送数据的长度，当然如果采用 `Gzip` 压缩的话，`Content-Length` 设置的就是压缩后的传输长度，另外

* `Content-Length` 如果存在并且有效的话，则必须和消息内容的传输长度完全一致，也就是说，如果过短就会截断，过长的话，就会导致超时
* 如果采用短链接的话，直接可以通过服务器关闭连接来确定消息的传输长度
* 那么在 `HTTP/1.0` 之前的版本中，`Content-Length` 字段可有可无，因为一旦服务器关闭连接，我们就可以获取到传输数据的长度了
* 在 `HTTP/1.1` 版本中，如果是 `keep-alive` 的话，`chunked` 优先级高于 `Content-Length`，若是非 `keep-alive`，则跟前面情况一样，`Content-Length` 可有可无

下面我们来看看如何设置 `Content-Length`，代码如下

```js
const server = require('http').createServer()

server.on('request', (req, res) => {
  if (req.url === '/index') {
    // 设置数据类型    
    res.setHeader('Content-Type', 'text/plain')
    res.setHeader('Content-Length', 10)
    res.write(`使用 Content-Length 设置传输数据形式`)
  }
})

server.listen(3000, _ => {
  console.log(`app is running at port 3000`)
})
```

#### 不定长数据

现在采用最多的就是 `HTTP/1.1` 版本来完成传输数据，在保存 `keep-alive` 状态下，当数据是不定长的时候，我们需要设置新的头部字段 `Transfer-Encoding: chunked`，通过 `chunked` 机制，可以完成对不定长数据的处理，但是也有需要注意的地方

* 如果头部信息中有 `Transfer-Encoding`，优先采用 `Transfer-Encoding` 里面的方法来找到对应的长度
* 如果设置了 `Transfer-Encoding`，那么 `Content-Length` 将被忽视
* 使用长连接的话，会持续的推送动态内容

```js
const server = require('http').createServer()

server.on('request', (req, res) => {
  if (req.url === '/index') {
    // 设置数据类型    
    res.setHeader('Content-Type', 'text/html; charset=utf8')
    res.setHeader('Content-Length', 10)
    res.setHeader('Transfer-Encoding', 'chunked')
    res.write(`使用 Content-Length 设置传输数据形式`)
    setTimeout(() => {
      res.write(`第一次的数据`)
    }, 1000)
    res.write(`----`)
    setTimeout(() => {
      res.write(`第二次的数据`)
      res.end()
    }, 3000)
  }
})

server.listen(3000, _ => {
  console.log(`app is running at port 3000`)
})
```




## SSL 连接断开后如何恢复

一共有两种方法来恢复断开的 `SSL` 连接，一种是使用 `Session ID`，一种是 `Session Ticket`

#### 通过 Session ID

使用 `Session ID` 的方式，每一次的会话都有一个编号，当对话中断后，下一次重新连接时，只要客户端给出这个编号，服务器如果有这个编号的记录，那么双方就可以继续使用以前的秘钥，而不用重新生成一把，目前所有的浏览器都支持这一种方法，但是这种方法有一个缺点是，`Session ID` 只能够存在一台服务器上，如果我们的请求通过负载平衡被转移到了其他的服务器上，那么就无法恢复对话


#### 通过 Session Ticket

另一种方式是 `Session Ticket` 的方式，`Session Ticket` 是服务器在上一次对话中发送给客户的，这个 `Ticket` 是加密的，只有服务器能够解密，里面包含了本次会话的信息，比如对话秘钥和加密方法等，这样不管我们的请求是否转移到其他的服务器上，当服务器将 `Ticket` 解密以后，就能够获取上次对话的信息，就不用重新生成对话秘钥了



## 短轮询、长轮询和 WebSocket 间的区别？

* 短轮询
  * 短轮询的基本思路是，浏览器每隔一段时间向浏览器发送 `HTTP` 请求，服务器端在收到请求后，不论是否有数据更新，都直接进行响应，这种方式实现的即时通信，本质上还是浏览器发送请求，服务器接受请求的一个过程，通过让客户端不断的进行请求，使得客户端能够模拟实时地收到服务器端的数据的变化
  * 优缺点
    * 优点是比较简单，易于理解
    * 缺点是这种方式由于需要不断的建立 `HTTP` 连接，严重浪费了服务器端和客户端的资源，当用户增加时，服务器端的压力就会变大，这是很不合理的
* 长轮询
  * 长轮询的基本思路，首先由客户端向服务器发起请求，当服务器收到客户端发来的请求后，服务器端不会直接进行响应，而是先将这个请求挂起，然后判断服务器端数据是否有更新，如果有更新，则进行响应，如果一直没有数据，则到达一定的时间限制才返回，客户端 `JavaScript` 响应处理函数会在处理完服务器返回的信息后，再次发出请求，重新建立连接
  * 优缺点
    * 长轮询和短轮询比起来，它的优点是明显减少了很多不必要的 `HTTP` 请求次数，相比之下节约了资源
    * 长轮询的缺点在于，连接挂起也会导致资源的浪费
* `WebSocket`
  * `WebSocket` 是 `HTML5` 定义的一个新协议，与传统的 `HTTP` 协议不同，该协议允许由服务器主动的向客户端推送信息
  * 优缺点
    * 优点是 `WebSocket` 是一个全双工的协议，也就是通信双方是平等的，可以相互发送消息
    * 缺点在于如果需要使用 `WebSocket` 协议，服务器端的配置比较复杂



## 正向代理和反向代理

* 正向代理，我们常说的代理也就是指正向代理，正向代理的过程，它隐藏了真实的请求客户端，服务端不知道真实的客户端是谁，客户端请求的服务都被代理服务器代替来请求
* 反向代理，这种代理模式下，它隐藏了真实的服务端，当我们向一个网站发起请求的时候，背后可能有成千上万台服务器为我们服务，具体是哪一台，我们不清楚，我们只需要知道反向代理服务器是谁就行，而且反向代理服务器会帮我们把请求转发到真实的服务器那里去，一般而言反向代理服务器一般用来实现负载平衡


## 负载平衡的两种实现方式

* 一种是使用反向代理的方式，用户的请求都发送到反向代理服务上，然后由反向代理服务器来转发请求到真实的服务器上，以此来实现集群的负载平衡
* 另一种是 `DNS` 的方式，`DNS` 可以用于在冗余的服务器上实现负载平衡，因为现在一般的大型网站使用多台服务器提供服务，因此一个域名可能会对应多个服务器地址，当用户向网站域名请求的时候，`DNS` 服务器返回这个域名所对应的服务器 `IP` 地址的集合，但在每个回答中，会循环这些 `IP` 地址的顺序，用户一般会选择排在前面的地址发送请求，以此将用户的请求均衡的分配到各个不同的服务器上，这样来实现负载均衡

但是 `DNS` 的方式有一个缺点就是，由于 `DNS` 服务器中存在缓存，所以有可能一个服务器出现故障后，域名解析仍然返回的是那个 `IP` 地址，就会造成访问的问题


