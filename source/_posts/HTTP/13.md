---
title: HTTP 查漏补缺
date: 2020-09-19
categories: HTTP
tags: HTTP
toc: true
thumbnail: https://gitee.com/heptaluan/backups/raw/master/cdn/cover/13.jpg
---

本章记录的是一些 `HTTP` 相关内容的补充，偏向于查漏补缺，主要是一些平常遇到或是看到过的知识点，面试题之类的，在这里简单的整理汇总一下，一方面补充些专业知识，另一方面也是方便以后查询或是复习，更多相关内容可以参考 [计算机网络知识梳理](https://heptaluan.github.io/2020/08/08/HTTP/00/) 和 [前端知识体系整理](https://heptaluan.github.io/target/)

<!--more-->


## HTTP 协议优缺点

* `HTTP` 特点
  * 灵活可扩展，一个是语法上只规定了基本格式，空格分隔单词，换行分隔字段等，另外一个就是传输形式上不仅可以传输文本，还可以传输图片，视频等任意数据
  * 请求/响应 模式，通常而言，就是一方发送消息，另外一方要接受消息，或者是做出相应等
  * 可靠传输，`HTTP` 是基于 `TCP/IP`，`TCP` 提供可靠的字节流服务，`IP` 协议的作用是把各种数据传送给对方
* `HTTP` 缺点
  * 无连接，限制每次连接只处理一个请求，服务器处理完客户的请求，并收到客户的应答后，即断开连接
  * 无状态，对于事务处理没有记忆能力，即服务器不知道客户端是什么状态
  * 明文传输，协议里的报文不使用二进制数据，而是文本形式，这让 `HTTP` 的报文信息暴露给了外界，给攻击者带来了便利
  * 队头阻塞，当 `HTTP` 开启长连接时，共用一个 `TCP` 连接，当某个请求时间过长时，其他的请求只能处于阻塞状态，这就是队头阻塞问题


## HTTP 协议各版本差异

* `HTTP/0.9`
  * `1991` 年发布的原型版本，功能简陋，只有一个命令 `GET`，只支持纯文本内容
* `HTTP/1.0`
  * 任何格式的内容都可以发送，另外还引入了 `POST` 命令和 `HEAD` 命令
  * `HTTP` 请求和回应的格式改变，除了数据部分，每次通信都必须包括头信息，用来描述一些元数据
  * 只使用请求头中的 `If-Modified-Since` 和 `Expires` 字段作为缓存失效的标准
  * 不支持断点续传，也就是说，每次都会传送全部的页面和数据
  * 通常每台计算机只能绑定一个 `IP`，所以请求消息中的 `URL` 并没有传递主机名
* `HTTP/1.1`
  * 引入了持久连接
    * `TCP` 连接默认不关闭，可以被多个请求复用，不用声明 `Connection: keep-alive`，长连接的连接时长可以通过请求头中的 `keep-alive` 来设置
  * 引入了管线机制（`Pipelining`）
    * 在同一个 `TCP` 连接里，客户端可以同时发送多个请求
  * 新增缓存控制标头
    * 添加了 `E-tag`，`If-Unmodified-Since`，`If-Match`，`If-None-Match` 等缓存控制标头来控制缓存失效
  * 支持断点续传
    * 通过使用请求头中的 `Range` 来实现
  * 使用了虚拟网络
    * 在一台物理服务器上可以存在多个虚拟主机，并且它们共享一个 `IP` 地址
  * 新增方法 `PUT`、`PATCH`、`OPTIONS`、`DELETE`
* `HTTP/2`
  * 二进制分帧
    * 采用二进制格式，这样报文格式就被拆分为一个个乱序的二进制帧，用 `Headers` 帧存放头部字段，`Data` 帧存放请求体数据等，因为不需要排队等待，一定程度上解决了队头阻塞问题
  * 头部压缩
    * `HTTP/1.1` 版本会出现 `User-Agent/Cookie/Accept/Server/Range` 等字段可能会占用几百甚至几千字节，而 `Body` 却经常只有几十字节，导致头部偏重，`HTTP/2` 使用 `HPACK` 算法进行压缩
  * 多路复用
    * 复用 `TCP` 连接，在一个连接里，客户端和浏览器都可以同时发送多个请求或回应，且不用按顺序一一对应，一定程度上解决了队头阻塞的问题
  * 服务器推送
    * 允许服务器未经请求，主动向客户端发送资源，即服务器推送
  * 请求优先级
    * 可以设置数据帧的优先级，让服务端先处理重要资源，优化用户体验
* `HTTP/3`
  * `QUIC` 协议
    * 运行在 `QUIC` 之上的 `HTTP` 协议被称为 `HTTP/3`，`QUIC` 协议基于 `UDP` 实现，同时也整合了 `TCP`、`TLS` 和 `HTTP/2` 的优点，并加以优化
  * 零 `RTT` 建立连接
    * 首次连接只需要 `1 RTT`，后面的连接更是只需 `0 RTT`，意味着客户端发给服务端的第一个包就带有请求数据
  * 连接迁移
    * `QUIC` 连接不以四元组（源 `IP`、源端口、目的 `IP`、目的端口）作为标识，而是使用一个 `64` 位的随机数，这个随机数被称为 `Connection ID`，即使 `IP` 或者端口发生变化，只要 `Connection ID` 没有变化，那么连接依然可以维持
  * 多路复用
    * `QUIC` 的传输单元是 `Packet`，加密单元也是 `Packet`，整个加密、传输、解密都基于 `Packet`，这样就能避免 `TLS` 的队头阻塞问题
    * `QUIC` 基于 `UDP`，`UDP` 的数据包在接收端没有处理顺序，即使中间丢失一个包，也不会阻塞整条连接，其他的资源会被正常处理
  * 改进的拥塞控制
    * 热插拔，`TCP` 中如果要修改拥塞控制策略，需要在系统层面进行操作，`QUIC` 修改拥塞控制策略只需要在应用层操作，并且 `QUIC` 会根据不同的网络环境、用户来动态选择拥塞控制算法
    * 前向纠错 `FEC`，使用前向纠错（`FEC`，`Forward Error Correction`）技术增加协议的容错性，一段数据被切分为 `10` 个包后，依次对每个包进行异或运算，运算结果会作为 `FEC` 包与数据包一起被传输，如果不幸在传输过程中有一个数据包丢失，那么就可以根据剩余 `9` 个包以及 `FEC` 包推算出丢失的那个包的数据
    * 单调递增的 `Packet Number`，与 `TCP` 的 `Sequence Number` 不同的是，`Packet Number` 严格单调递增，如果 `Packet N` 丢失了，那么重传时 `Packet` 的标识不会是 `N`，而是比 `N` 大的数字，比如 `N + M`，这样发送方接收到确认消息时就能方便地知道 `ACK` 对应的是原始请求还是重传请求
    * 更多的 `ACK` 块，`QUIC` 最多可以捎带 `256` 个 `ACK block`，在丢包率比较严重的网络下，更多的 `ACK block` 可以减少重传量，提升网络效率
  * 流量控制
    * `TCP` 会对每个 `TCP` 连接进行流量控制，而 `QUIC` 只需要建立一条连接，在这条连接上同时传输多条 `Stream`



## 队头阻塞问题

关于队头阻塞问题，其实在整理 `HTTP/1.1`，`HTTP/2` 和 `HTTP/3` 相关内容的时候都有所涉及，但是可能是东一点西一点分散在各处，所以在这里就简单的汇总和梳理一下


#### 什么是队头阻塞？

对于每一个 `HTTP` 请求而言，这些任务是会被放入一个任务队列中串行执行的，一旦队首任务请求太慢时，就会阻塞后面的请求处理，这就是 `HTTP` 队头阻塞问题，队头阻塞会导致带宽无法被充分利用，以及后续健康请求被阻塞，假设有五个请求同时发出，如下图

![](https://gitee.com/heptaluan/backups/raw/master/cdn/http/11-01.png)

在第一个请求没有收到回复之前，后续从应用层发出的请求只能排队，请求 `2，3，4，5` 只能等待请求 `1` 的响应回来之后才能逐个发出，网络通畅的时候性能影响不大，一旦请求 `1` 因为什么原因没有抵达服务器，或者响应因为网络阻塞没有及时返回，影响的就是所有后续请求


#### 如何解决

在 `HTTP/1.1` 当中，为了解决队头阻塞带来的延迟，协议设计者设计了一种新的 `HTTP` 管线化机制（`pipelining`），管线化的流程图可以用下图表示

![](https://gitee.com/heptaluan/backups/raw/master/cdn/http/11-04.png)

和之前相比最大的差别是，请求 `2，3，4，5` 不需要等待请求 `1` 的响应返回之后才发出，而是几乎在同一时间就把请求发向了服务器，`2，3，4，5` 及所有后续共用该连接的请求节约了等待的时间，极大的降低了整体延迟，下图可以清晰的看出这种新机制对延迟的改变

![](https://gitee.com/heptaluan/backups/raw/master/cdn/http/11-05.png)

不过管线化并不是完美的，它也存在不少缺陷

* 管线化只能适用于 `HTTP/1.1` ，一般来说，支持 `HTTP/1.1` 的服务端都要求支持管线化
* 只有幂等的请求（`GET`，`HEAD`）能使用管线化，非幂等请求比如 `POST` 不能使用，因为请求之间可能会存在先后依赖关系
* 队头阻塞并没有完全得到解决，服务端的响应还是要求依次返回，遵循 `FIFO`（`first in first out`）原则，也就是说如果请求 `1` 的响应没有回来，`2，3，4，5` 的响应也不会被送回来
* 绝大部分的 `HTTP` 代理服务器不支持管线化

正是因为有这么多的问题，各大浏览器厂商要么是根本就不支持管线化，要么就是默认关掉了管线化机制，而且启用的条件十分苛刻，可以参考 `Chrome` 对于管线化的 [问题描述](https://www.chromium.org/developers/design-documents/network-stack/http-pipelining)

接下来，在 `HTTP/2` 当中提出了多路复用（`multiplexing`）的解决方案（源自 `SPDY`），多路复用允许同时通过单一的 `HTTP/2` 连接发起多重的 请求/响应 消息，众所周知在 `HTTP/1.1` 协议中，浏览器客户端在同一时间，针对同一域名下的请求有一定数量限制，超过限制数目的请求会被阻塞，也就是如果想并发多个请求，必须使用多个 `TCP` 链接

这也是为何一些站点会有多个静态资源 `CDN` 域名的原因之一，目的就是变相的解决浏览器针对同一域名的请求限制阻塞问题，而 `HTTP/2` 的多路复用（`Multiplexing`）则允许同时通过单一的 `HTTP/2` 连接发起多重的 请求/响应 消息

![](https://gitee.com/heptaluan/backups/raw/master/cdn/http/11-15.png)

因此 `HTTP/2` 可以很容易的去实现多流并行而不用依赖建立多个 `TCP` 连接，`HTTP/2` 把 `HTTP` 协议通信的基本单位缩小为一个一个的帧，这些帧对应着逻辑流中的消息，并行地在同一个 `TCP` 连接上双向交换消息

`HTTP/2` 虽然可以解决请求这个粒度的阻塞，但 `HTTP/2` 的基础 `TCP` 协议本身却也存在着队头阻塞的问题，`HTTP/2` 的每个请求都会被拆分成多个 `Frame`，不同请求的 `Frame` 组合成 `Stream`，`Stream` 是 `TCP` 上的逻辑传输单元，这样 `HTTP/2` 就达到了一条连接同时发送多条请求的目标，这就是多路复用的原理

我们看一个例子，在一条 `TCP` 连接上同时发送 `4` 个 `Stream`，其中 `Stream1` 已正确送达，`Stream2` 中的第 `3` 个 `Frame` 丢失，`TCP` 处理数据时有严格的前后顺序，先发送的 `Frame` 要先被处理，这样就会要求发送方重新发送第 `3` 个 `Frame`，`Stream3` 和 `Stream4` 虽然已到达但却不能被处理，那么这时整条连接都被阻塞

![](https://gitee.com/heptaluan/backups/raw/master/cdn/http/12-09.png)

不仅如此，由于 `HTTP/2` 必须使用 `HTTPS`，而 `HTTPS` 使用的 `TLS` 协议也存在队头阻塞问题，`TLS` 基于 `Record` 组织数据，将一堆数据放在一起（即一个 `Record`）加密，加密完后又拆分成多个 `TCP` 包传输，一般每个 `Record` 有 `16K` 左右，包含 `12` 个 `TCP` 包，这样如果 `12` 个 `TCP` 包中有任何一个包丢失，那么整个 `Record` 都无法解密

![](https://gitee.com/heptaluan/backups/raw/master/cdn/http/12-10.png)

队头阻塞会导致 `HTTP/2` 在更容易丢包的弱网络环境下比 `HTTP/1.1` 更慢，所以就有了 `HTTP/3` 当中的 `QUIC` 协议，那么 `QUIC` 是如何解决队头阻塞问题的呢？主要有两点

* `QUIC` 的传输单元是 `Packet`，加密单元也是 `Packet`，整个加密、传输、解密都基于 `Packet`，这样就能避免 `TLS` 的队头阻塞问题
* `QUIC` 基于 `UDP`，`UDP` 的数据包在接收端没有处理顺序，即使中间丢失一个包，也不会阻塞整条连接，其他的资源会被正常处理

![](https://gitee.com/heptaluan/backups/raw/master/cdn/http/12-11.png)


## HTTP 数据传输

这里主要分为定长数据与不定长数据的处理，我们一个一个来看

#### 定长数据

对于定长的数据包而言，发送端在发送数据的过程中，需要设置 `Content-Length`，来指明发送数据的长度，当然如果采用 `Gzip` 压缩的话，`Content-Length` 设置的就是压缩后的传输长度，另外

* `Content-Length` 如果存在并且有效的话，则必须和消息内容的传输长度完全一致，也就是说，如果过短就会截断，过长的话，就会导致超时
* 如果采用短链接的话，直接可以通过服务器关闭连接来确定消息的传输长度
* 那么在 `HTTP/1.0` 之前的版本中，`Content-Length` 字段可有可无，因为一旦服务器关闭连接，我们就可以获取到传输数据的长度了
* 在 `HTTP/1.1` 版本中，如果是 `keep-alive` 的话，`chunked` 优先级高于 `Content-Length`，若是非 `keep-alive`，则跟前面情况一样，`Content-Length` 可有可无

下面我们来看看如何设置 `Content-Length`，代码如下

```js
const server = require('http').createServer()

server.on('request', (req, res) => {
  if (req.url === '/index') {
    // 设置数据类型    
    res.setHeader('Content-Type', 'text/plain')
    res.setHeader('Content-Length', 10)
    res.write(`使用 Content-Length 设置传输数据形式`)
  }
})

server.listen(3000, _ => {
  console.log(`app is running at port 3000`)
})
```

#### 不定长数据

现在采用最多的就是 `HTTP/1.1` 版本来完成传输数据，在保存 `keep-alive` 状态下，当数据是不定长的时候，我们需要设置新的头部字段 `Transfer-Encoding: chunked`，通过 `chunked` 机制，可以完成对不定长数据的处理，但是也有需要注意的地方

* 如果头部信息中有 `Transfer-Encoding`，优先采用 `Transfer-Encoding` 里面的方法来找到对应的长度
* 如果设置了 `Transfer-Encoding`，那么 `Content-Length` 将被忽视
* 使用长连接的话，会持续的推送动态内容

```js
const server = require('http').createServer()

server.on('request', (req, res) => {
  if (req.url === '/index') {
    // 设置数据类型    
    res.setHeader('Content-Type', 'text/html; charset=utf8')
    res.setHeader('Content-Length', 10)
    res.setHeader('Transfer-Encoding', 'chunked')
    res.write(`使用 Content-Length 设置传输数据形式`)
    setTimeout(() => {
      res.write(`第一次的数据`)
    }, 1000)
    res.write(`----`)
    setTimeout(() => {
      res.write(`第二次的数据`)
      res.end()
    }, 3000)
  }
})

server.listen(3000, _ => {
  console.log(`app is running at port 3000`)
})
```




## SSL 连接断开后如何恢复

一共有两种方法来恢复断开的 `SSL` 连接，一种是使用 `Session ID`，一种是 `Session Ticket`

#### 通过 Session ID

使用 `Session ID` 的方式，每一次的会话都有一个编号，当对话中断后，下一次重新连接时，只要客户端给出这个编号，服务器如果有这个编号的记录，那么双方就可以继续使用以前的秘钥，而不用重新生成一把，目前所有的浏览器都支持这一种方法，但是这种方法有一个缺点是，`Session ID` 只能够存在一台服务器上，如果我们的请求通过负载平衡被转移到了其他的服务器上，那么就无法恢复对话


#### 通过 Session Ticket

另一种方式是 `Session Ticket` 的方式，`Session Ticket` 是服务器在上一次对话中发送给客户的，这个 `Ticket` 是加密的，只有服务器能够解密，里面包含了本次会话的信息，比如对话秘钥和加密方法等，这样不管我们的请求是否转移到其他的服务器上，当服务器将 `Ticket` 解密以后，就能够获取上次对话的信息，就不用重新生成对话秘钥了



## 短轮询、长轮询和 WebSocket 间的区别

* 短轮询
  * 短轮询的基本思路是，浏览器每隔一段时间向浏览器发送 `HTTP` 请求，服务器端在收到请求后，不论是否有数据更新，都直接进行响应，这种方式实现的即时通信，本质上还是浏览器发送请求，服务器接受请求的一个过程，通过让客户端不断的进行请求，使得客户端能够模拟实时地收到服务器端的数据的变化
  * 优缺点
    * 优点是比较简单，易于理解
    * 缺点是这种方式由于需要不断的建立 `HTTP` 连接，严重浪费了服务器端和客户端的资源，当用户增加时，服务器端的压力就会变大，这是很不合理的
* 长轮询
  * 长轮询的基本思路，首先由客户端向服务器发起请求，当服务器收到客户端发来的请求后，服务器端不会直接进行响应，而是先将这个请求挂起，然后判断服务器端数据是否有更新，如果有更新，则进行响应，如果一直没有数据，则到达一定的时间限制才返回，客户端 `JavaScript` 响应处理函数会在处理完服务器返回的信息后，再次发出请求，重新建立连接
  * 优缺点
    * 长轮询和短轮询比起来，它的优点是明显减少了很多不必要的 `HTTP` 请求次数，相比之下节约了资源
    * 长轮询的缺点在于，连接挂起也会导致资源的浪费
* `WebSocket`
  * `WebSocket` 是 `HTML5` 定义的一个新协议，与传统的 `HTTP` 协议不同，该协议允许由服务器主动的向客户端推送信息
  * 优缺点
    * 优点是 `WebSocket` 是一个全双工的协议，也就是通信双方是平等的，可以相互发送消息
    * 缺点在于如果需要使用 `WebSocket` 协议，服务器端的配置比较复杂



至于什么是单工、半双工、全双工，区别如下表所示

类型 |	能力
-|-
单工 |	信息单向传送
半双工 |	信息能双向传送，但不能同时双向传送
全双工 |	信息能够同时双向传送


## 正向代理和反向代理

* 正向代理，我们常说的代理也就是指正向代理，正向代理的过程，它隐藏了真实的请求客户端，服务端不知道真实的客户端是谁，客户端请求的服务都被代理服务器代替来请求
* 反向代理，这种代理模式下，它隐藏了真实的服务端，当我们向一个网站发起请求的时候，背后可能有成千上万台服务器为我们服务，具体是哪一台，我们不清楚，我们只需要知道反向代理服务器是谁就行，而且反向代理服务器会帮我们把请求转发到真实的服务器那里去，一般而言反向代理服务器一般用来实现负载平衡


## 负载平衡的两种实现方式

* 一种是使用反向代理的方式，用户的请求都发送到反向代理服务上，然后由反向代理服务器来转发请求到真实的服务器上，以此来实现集群的负载平衡
* 另一种是 `DNS` 的方式，`DNS` 可以用于在冗余的服务器上实现负载平衡，因为现在一般的大型网站使用多台服务器提供服务，因此一个域名可能会对应多个服务器地址，当用户向网站域名请求的时候，`DNS` 服务器返回这个域名所对应的服务器 `IP` 地址的集合，但在每个回答中，会循环这些 `IP` 地址的顺序，用户一般会选择排在前面的地址发送请求，以此将用户的请求均衡的分配到各个不同的服务器上，这样来实现负载均衡

但是 `DNS` 的方式有一个缺点就是，由于 `DNS` 服务器中存在缓存，所以有可能一个服务器出现故障后，域名解析仍然返回的是那个 `IP` 地址，就会造成访问的问题





## HTTP 缓存策略

关于缓存策略，我们之前在 [浏览器缓存机制](https://heptaluan.github.io/2019/11/12/HTTP/04/) 一节当中已经详细整理过，这里我们在简单梳理一下，总的分为两种策略，即强缓存和协商缓存，下面我们一个一个来看


#### 强缓存

简单总结一下

* 强缓存有两个相关字段，`Expires` 和 `Cache-Control`
* 分为两种情况，一种是发送 `HTTP` 请求，一种不需要发送
* 首先检查强缓存，这个阶段不需要发送 `HTTP` 请求，通过查找不同的字段来进行，不同的 `HTTP` 版本所以不同
* `HTTP/1.0` 版本，使用的是 `Expires`，`HTTP/1.1` 使用的是 `Cache-Control`

###### Expires

`Expires` 即过期时间，时间是相对于服务器的时间而言的，存在于服务端返回的响应头中，在这个过期时间之前可以直接从缓存里面获取数据，无需再次请求，比如下面这样

```js
Expires: Mon, 29 Jun 2019 11:10:23 GMT
```

表示该资源在 `2019` 年 `7` 月 `29` 日 `11:10:23` 过期，过期时就会重新向服务器发起请求，但是这种方式是存在一些问题的，比如服务器的时间和浏览器的时间可能并不一致，所以 `HTTP/1.1` 提出新的字段代替它


###### Cache-Control

`HTTP/1.1` 版本中，使用的就是该字段，这个字段采用的时间是过期时长，对应的是 `max-age`

```js
Cache-Control: max-age = 6000
```

上面代表该资源返回后 `6000` 秒，可以直接使用缓存，还有其他一些相关指令，使用方式可以参考上文链接，这里需要注意的几点

* 当 `Expires` 和 `Cache-Control` 同时存在时，优先考虑 `Cache-Control`
* 当缓存资源失效了，也就是没有命中强缓存，接下来就进入协商缓存



#### 协商缓存

强缓存失效后，浏览器在请求头中携带响应的缓存 `Tag` 来向服务器发送请求，服务器根据对应的 `Tag`，来决定是否使用缓存

缓存分为两种，`Last-Modified` 和 `ETag`，两者各有优势，并不存在谁对谁有绝对的优势，这点与上面所讲的强缓存当中的两个 `Tag` 有所不同

###### Last-Modified

这个字段表示的是最后修改时间，在浏览器第一次给服务器发送请求后，服务器会在响应头中加上这个字段，浏览器接收到后，如果再次请求，会在请求头中携带 `If-Modified-Since` 字段，这个字段的值也就是服务器传来的最后修改时间，服务器拿到请求头中的 `If-Modified-Since` 的字段后，其实会和这个服务器中该资源的最后修改时间对比

* 如果请求头中的这个值小于最后修改时间，说明是时候更新了，返回新的资源，跟常规的 `HTTP` 请求响应的流程一样
* 否则返回 `304`，告诉浏览器直接使用缓存

###### ETag

`ETag` 是服务器根据当前文件的内容，对文件生成唯一的标识，比如 `MD5` 算法，只要里面的内容有改动，这个值就会修改，服务器通过把响应头把该字段给浏览器，浏览器接收到 `ETag` 值，会在下次请求的时候，将这个值作为 `If-None-Match` 这个字段的内容，发给服务器

服务器接收到 `If-None-Match` 后，会跟服务器上该资源的 `ETag` 进行比对

* 如果两者一样的话，直接返回 `304`，告诉浏览器直接使用缓存
* 如果不一样的话，说明内容更新了，返回新的资源，跟常规的 `HTTP` 请求响应的流程一样


###### 两者对比

* 性能上，`Last-Modified` 优于 `ETag`，`Last-Modified` 记录的是时间点，而 `Etag` 需要根据文件的 `MD5` 算法生成对应的 `Hash` 值
* 精度上，`ETag` 优于 `Last-Modified`，`ETag` 按照内容给资源带上标识，能准确感知资源变化，`Last-Modified` 在某些场景并不能准确感知变化，比如
  * 编辑了资源文件，但是文件内容并没有更改，这样也会造成缓存失效
  * `Last-Modified` 能够感知的单位时间是秒，如果文件在 `1` 秒内改变了多次，那么这时候的 `Last-Modified` 并没有体现出修改了

最后，如果两种方式都支持的话，服务器会优先考虑 `ETag`


#### 缓存位置

下面我们来看看，如果考虑使用缓存的话，那么缓存的位置在哪里呢？其实浏览器缓存的位置的话，可以分为四种，优先级从高到低排列分别

* `Service Worker`
* `Memory Cache`
* `Disk Cache`
* `Push Cache`

###### Service Worker

`Service Worker` 的缓存与浏览器其他内建的缓存机制不同，它可以让我们自由控制缓存哪些文件、如何匹配缓存、如何读取缓存，并且缓存是持续性的

`PWA` 的实现也是和这个有关，它借鉴了 `Web Worker` 思路，由于它脱离了浏览器的窗体，因此无法直接访问 `DOM`，它能完成的功能比如离线缓存、消息推送和网络代理，其中离线缓存就是 `Service Worker Cache`


###### Memory Cache

指的是内存缓存，从效率上讲它是最快的，从存活时间来讲又是最短的，当渲染进程结束后，内存缓存也就不存在了


###### Disk Cache

存储在磁盘中的缓存，从存取效率上讲是比内存缓存慢的，优势在于存储容量和存储时长，与 `Memory Cache` 对比的话，主要的策略如下

* 内容使用率高的话，文件优先进入磁盘
* 比较大的 `JavaScript`，`CSS` 文件会直接放入磁盘，反之放入内存


###### Push Cache

`Push Cache`（推送缓存）是 `HTTP/2` 中的内容，当以上三种缓存都没有命中时，它才会被使用，它只在会话（`Session`）中存在，一旦会话结束就被释放，并且缓存时间也很短暂，在 `Chrome` 浏览器中只有五分钟左右

更多 `Push Cache` 更多内容可以参考 [HTTP/2 push is tougher than I thought](https://jakearchibald.com/2017/h2-push-tougher-than-i-thought/)


#### 总结

* 首先检查 `Cache-Control`，看强缓存是否可用如果可用的话，直接使用
* 否则进入协商缓存，发送 `HTTP` 请求，服务器通过请求头中的 `If-Modified-Since` 或者 `If-None-Match` 字段检查资源是否更新资源更新，返回资源和 `200` 状态码
* 否则返回 `304`，直接告诉浏览器直接从缓存中去资源

## TCP 如何保证可靠传输

`TCP` 协议保证数据传输可靠性的方式主要有以下几种方式

* 校验和，`TCP` 在发送报文之前，发送方要计算校验和，收到数据后，接收方也要计算校验和，如果校验和不相等则丢弃
* 序列号与确认应答
  * 序列号，`TCP` 传输时将每个字节的数据都进行了编号，这就是序列号
  * 确认应答，`TCP` 传输的过程中，每次接收方收到数据后，都会对传输方进行确认应答，也就是发送 `ACK` 报文，这个 `ACK` 报文当中带有对应的确认序列号，告诉发送方，接收到了哪些数据，下一次的数据从哪里发
  * 序列号的作用不仅仅是应答的作用，有了序列号能够将接收到的数据根据序列号排序，并且去掉重复序列号的数据，这也是 `TCP` 传输可靠性的保证之一
* 超时重传，在 `TCP` 传输过程中，我们在发送一部分数据后，都会等待对方的 `ACK` 确认报文，如果中间出现差错，没有收到 `ACK` 报文，这时候需要启动超时重传机制，这种超时重传机制保证了 `TCP` 在网络延迟或者报文丢失下的可靠传输，超时的原因主要有以下两点
  * 接收方没有收到 `TCP` 报文段，网络延迟或者丢包
  * 发送方没有收到 `ACK` 报文段，网络延迟或者 `ACK` 报文丢失
* 连接管理，连接管理就是三次握手与四次挥手的过程
* 流量控制，流量控制的目的是让接收方来得及接收数据，这样避免了数据丢包以及网络拥塞等情况
* 拥塞控制，拥塞控制就是防止过多的数据注入到网络中，这样使网络中的路由器或者链路不至于过载（四个核心算法，慢启动、拥塞避免、快速重传和快速恢复）


## 三次握手

`TCP` 建立连接的过程叫做握手，握手需要在客户和服务器之间交换三个 `TCP` 报文段，也叫三报文握手

![](https://gitee.com/heptaluan/backups/raw/master/cdn/http/13-01.png)

* `A` 主动打开连接，`B` 被动打开连接，`B` 先进入收听状态（`LISTEN`），`A` 打算建立 `TCP` 连接时，先向 `B` 发送连接请求报文段，其中同步位 `SYN = 1`，初始序号 `seq = x`，这个报文段不能携带数据，但是要消耗一个序号，接着 `A` 进入同步已发送状态
*  `B` 收到请求报文段，如果同意建立连接，则向 `A` 发送 `ACK` 确认报文段，其中同步位 `SYN = 1`，确认号 `ACK = 1`，初始序号 `seq = y`，确认号 `ack = x + 1`（请求报文段消耗了一个序号），这个 `ACK` 报文段也不能携带数据，但是要消耗一个序号，与此同时 `B` 进入到同步收到的状态
* `A` 收到 `B` 的确认报文后，还要给 `B` 发送确认报文，其中 `ACK = 1`， `seq = x + 1`（上一个报文段的 `ack`），`ack = y + 1`（上一个报文段的 `seq + 1`，因为消耗了一个序号），这个 `ACK` 报文段可以携带数据，但是如果不携带数据则不会消耗序号，下一次 `A` 给 `B` 发送报文段的初始序号 `seq = 1`，此时 `A` 进入已建立连接的状态，`B` 收到确认后也进入已建立连接的状态

这里存在一个问题，那就是为什么需要最后一次确认？

其实简单来说，这是防止已失效的连接请求报文段突然又传送到了 `B` 而引发错误，但是有可能出现异常情况，即 `A` 发送的连接请求并没有丢失，而是滞留了在网络中，如果在传输数据完成之后，这个请求又发到 `B` ，`B` 误以为 `A` 还要发送数据，因此发送确认报文，但是 `A` 没有运输需求，因此不予理睬，如果没有最后一次确认，`B` 一直等待 `A` 的确认，这样会造成的浪费

采用三报文握手，如果 `B` 没有收到 `A` 的确认，则可以知道 `A` 没有建立连接的需求，就可以避免上述这种情况

> 所谓的失效的连接请求就是 `A` 第一次先发送了一个请求，但是丢失了，于是 `A` 再发送一个连接请求，重新建立连接，发送数据并释放连接



## 四次挥手

所谓的四次挥手其实也就是 `TCP` 的连接释放的过程

![](https://gitee.com/heptaluan/backups/raw/master/cdn/http/13-02.png)

* `A` 和 `B` 目前都处于已建立连接的状态，`A` 的应用进程向其 `TCP` 发出连接释放报文段，并停止发送数据，主动关闭 `TCP` 连接，此时 `FIN = 1`，`seq = u`，`u` 等于前面已发送的最后一个字节的序号加 `1`，这时 `A` 进入到 `FIN-WAIT-1`（终止等待 `1`）状态，等待 `B` 的确认，`FIN` 报文段即使不携带数据，也要消耗一个序号
* `B` 收到释放连接后立即发出确认，此时，`ACK = 1`，确认号是 `ack = u + 1`（前面的 `seq + 1`，因为消耗了一个序号），序号 `seq = v`，`v` 等于 `B` 前面所有已传送数据的最后一个字节的序号加 `1`，`B` 进入到 `CLOSE-WAIT`（关闭等待）状态，`TCP` 服务器进程向 `B` 的高层应用进程告知，此时 `A` 到 `B` 的连接已经释放，`TCP` 连接处于半关闭状态，但是，`B` 到 `A` 这个方向的连接尚未关闭
* `A` 收到 `B` 的确认后，就进入到 `FIN-WAIT-2`（终止等待 `2`）的状态，等待 `B` 发送连接释放报文段
* 若 `B` 已经没有数据需要发送，则应用进程通知 `TCP` 释放连接，这时 `B` 发送的报文段 `FIN = 1`，`ACK = 1`，`seq = w`（可能后面又发送了一些数据），`ack = u + 1`，并且这个报文消耗一个序号，`B` 进入到 `LAST-ACK`（最后确认）的状态，等待 `A` 的确认
* `A` 收到 `B` 的确认后，必须对此发送确认报文，该报文中 `ACK = 1`，`seq = u + 1`，`ack = w + 1`，然后进入到 `TIME-WAIT`（时间等待）状态

> 但是需要注意的是，此时 `TCP` 连接并没有完全释放，必须经过时间等待计时器设置的时间 `2MSL` 之后，`A` 才进入 `CLOSED` 状态，时间 `MSL` 叫做最大报文段寿命

那么问题来了，为什么要等待 `2MSL` 的时间呢？主要原因有两点

* 保证 `A` 最后发送的 `ACK` 报文段能够到达 `B`，因为这个报文可能丢失，因此 `B` 会重传最后一个确认报文段，`A` 再重新发送确认报文，并且重启计时器，直到 `A` ，`B` 都能正常进入到 `CLOSED` 状态
* 防止上面提到的已失效的连接请求报文，这段时间内，这些连接请求报文就可能在网络中消失
* 此外 `B` 要比 `A` 先进入 `CLOSED` 状态



