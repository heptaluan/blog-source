---
title: 背压
date: 2019-10-14
categories: Node.js
tags: Node.js
toc: true
thumbnail: https://gitee.com/heptaluan/backups/raw/master/cdn/cover/10.jpg
---

在上一章我们介绍可读流（`Readable Streams`）的时候，提及了一个背压的概念，我们本章就来探讨一下什么是背压

> 本篇内容主要参考自 [Backpressuring in Streams](https://nodejs.org/en/docs/guides/backpressuring-in-streams/)

<!--more-->


## 数据流中的积压问题

通常在数据处理的时候我们会遇到一个普遍的问题，那就是背压，意思是在数据传输过程中有一大堆数据在缓存之后积压着，每次当数据到达结尾又遇到复杂的运算，又或者无论什么原因它比预期的慢，这样累积下来，从源头来的数据就会变得很庞大，像一个塞子一样堵塞住

为解决这个问题，必须存在一种适当的代理机制，确保流从一个源流入另外一个的时候是平滑顺畅的，不同的社区组织针对他们各自的问题单独做了解决，好例子比如 `Unix` 的管道和 `TCP` 的 `Socket`，在 `Node.js` 中，流（`stream`）已经是被采纳的解决方案



## 数据太多，速度太快

有太多的例子证明有时 `Readable` 传输给 `Writable` 的速度远大于它接受和处理的速度，如果发生了这种情况，消费者开始为后面的消费而将数据列队形式积压起来，写入队列的时间越来越长，也正因为如此，更多的数据不得不保存在内存中知道整个流程全部处理完毕

写入磁盘的速度远比从磁盘读取数据慢得多，因此当我们试图压缩一个文件并写入磁盘时，积压的问题也就出现了，因为写磁盘的速度不能跟上读磁盘的速度

```js
// 数据将会在读入侧堆积，这样写入侧才能和数据流的读入速度保持同步
inp.pipe(gzip).pipe(outputFile)
```

这就是为什么说积压机制很重要，如果积压机制不存在，进程将用完你全部的系统内存，从而对其它进程产生显著影响，它独占系统大量资源直到任务完成为止，这最终将会导致一些问题

* 明显使得其它进程处理变慢
* 太多繁重的垃圾回收  
* 内存耗尽



## pipe 的背压平衡机制

假设现在有一对 `Readable` 和 `Writable`，要求编程实现从 `Readable` 里面读取数据然后写到 `Writable` 中，那么面临的问题很有可能就是如果两者对数据的产生/消费速度不一致，那么需要手动协调两者速度使得任务可以完成，思路可能这样

0. `Readable` 进入 `flowing` 模式，然后进入步骤 `2`
1. 听 `data` 事件，一旦有数据到达则进入步骤 `2`，如果捕捉到 `end` 事件就结束任务
2. 数据写入到 `Writable`，如果返回 `true` 进入步骤 `1`，否则进入步骤 `3`
3. `Readable` 进入 `pause` 模式，并等待 `Writable` 发射 `drain` 事件
4. 果 `Writable` 发射了 `drain` 事件，则返回步骤 `1`

而事实上 `pipe()` 的过程和上述很相似，它的源码如下

```js
Readable.prototype.pipe = function (dest, pipeOpts) {

  // ...

  var ondrain = pipeOnDrain(src)
  // 当写操作返回 false 的时候，正常情况下必然会在稍后触发一个 drain 事件
  dest.on('drain', ondrain)
  src.on('data', ondata)
  function ondata(chunk) {
    var ret = dest.write(chunk)
    // 如果写操作的返回值为 false，则暂停 readable 流
    if (ret === false) {
      if (((state.pipesCount === 1 && state.pipes === dest) ||
        (state.pipesCount > 1 && state.pipes.indexOf(dest) !== -1)) &&
        !cleanedUp) {
        state.awaitDrain++
      }
      src.pause()
    }
  }

  // ...

  return dest
}

function pipeOnDrain(src) {
  return function () {
    var state = src._readableState
    if (state.awaitDrain)
      state.awaitDrain--
    if (state.awaitDrain === 0 && EE.listenerCount(src, 'data')) {
      // 将流重新设为 flowing 模式
      state.flowing = true
      // 将缓冲区中残留的数据读取并重新触发 data 事件
      flow(src)
    }
  }
}
```

通过上面的代码我们可以看到

* 当向 `dest` 写入数据返回 `false` 时，马上调用 `src.pause()` 暂停流，`src.pause()` 将暂停事件流，但不会暂停数据生成
* 也就是说 `src` 此时依然汲取底层数据填充缓冲区，只是暂停发射 `data` 事件，等到缓冲区的数据量超过警戒线才会停止汲取
* 因为写入数据返回 `false`，因此在稍后的某个时候 `dest` 必然会发射 `drain` 事件
* 当 `drain` 事件发生后，`src` 再次进入 `flowing` 模式自动产生数据，同时将缓冲区中的残留数据写入 `dest`



## .pipe() 的生命周期

为了对积压有一个更好的理解，这里有一副 `Readable` 流正通过 `piped` 流入 `Writable` 流的整个生命周期图

```js
                                                     +===================+
                         x-->  Piping functions   +-->   src.pipe(dest)  |
                         x     are set up during     |===================|
                         x     the .pipe method.     |  Event callbacks  |
  +===============+      x                           |-------------------|
  |   Your Data   |      x     They exist outside    | .on('close', cb)  |
  +=======+=======+      x     the data flow, but    | .on('data', cb)   |
          |              x     importantly attach    | .on('drain', cb)  |
          |              x     events, and their     | .on('unpipe', cb) |
+---------v---------+    x     respective callbacks. | .on('error', cb)  |
|  Readable Stream  +----+                           | .on('finish', cb) |
+-^-------^-------^-+    |                           | .on('end', cb)    |
  ^       |       ^      |                           +-------------------+
  |       |       |      |
  |       ^       |      |
  ^       ^       ^      |    +-------------------+         +=================+
  ^       |       ^      +---->  Writable Stream  +--------->  .write(chunk)  |
  |       |       |           +-------------------+         +=======+=========+
  |       |       |                                                 |
  |       ^       |                              +------------------v---------+
  ^       |       +-> if (!chunk)                |    Is this chunk too big?  |
  ^       |       |     emit.end()               |    Is the queue busy?      |
  |       |       +-> else                       +-------+----------------+---+
  |       ^       |     emit.write()                     |                |
  |       ^       ^                                   +--v---+        +---v---+
  |       |       ^-----------------------------------<  No  |        |  Yes  |
  ^       |                                           +------+        +---v---+
  ^       |                                                               |
  |       ^               emit.pause()            +=================+     |
  |       ^---------------^-----------------------+  return false   <-----+---+
  |                                               +=================+         |
  |                                                                           |
  ^            when queue is empty     +============+                         |
  ^------------^-----------------------<  Buffering |                         |
               |                       |============|                         |
               +> emit.drain()         |  ^Buffer^  |                         |
               +> emit.resume()        +------------+                         |
                                       |  ^Buffer^  |                         |
                                       +------------+   add chunk to queue    |
                                       |            <---^---------------------<
                                       +============+
```

注意，如果你创建一些管道准备把一些流串联起来从而操纵数据，你应该实现 `Transform` 流，在这种情况下，从 `Readable` 流中的输出进入 `Transform`，并且会被管道输送进入 `Writable`

```js
Readable.pipe(Transformable).pipe(Writable)
```

积压将被自动应用，但是同时请注意输入和输出 `Transform` 的水准值，可以手动控制，并且会影响到积压系统，如果想要了解更多，可以参考 [通过源码解析 Node.js 中导流（pipe）的实现](https://cnodejs.org/topic/56ba030271204e03637a3870) 这篇文章